{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# FStrings\n",
    "\n",
    "Esta tabla contiene la información adicional de las sentencias de tipo JoinedStr (Strings formateados).  --> ABEL COMPLETAR <--"
   ],
   "id": "148ae8871134f924"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1 - Obtencion de datos",
   "id": "d3c24a719032807f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T14:03:16.967513Z",
     "start_time": "2024-05-15T14:03:11.665722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from notebooks_utils import *\n",
    "\n",
    "full_table = get_data('fstrings')\n",
    "\n",
    "# Table name, features and target.\n",
    "TABLE_NAME = 'fstrings'\n",
    "TABLE_FEATURES = ['fstring__number_of_elements', 'fstring__constants_pct', 'fstring__expressions_pct', 'fstring__expertise_level']\n",
    "TABLE_TARGET = 'fstring__expertise_level'\n",
    "\n",
    "# Load features and target.\n",
    "X, y = full_table[TABLE_FEATURES], full_table[[TABLE_TARGET]].iloc[:,0]\n",
    "\n",
    "# Print information about the loaded table.\n",
    "print(f'Features shape: {X.shape}')\n",
    "print(f'Target shape: {y.shape}')\n",
    "\n",
    "print(f'As we can see the downloaded data contains a total of {X.shape[0]} instances. Each of the instances corresponds to a program. For each program we have {X.shape[1]} attributes.')"
   ],
   "id": "9f0a949e91eb384b",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2 - Exploracion de datos\n",
    "\n",
    "Una vez tenemos nuestra tabla en un dataframe el siguiente paso es explorarla para ver qué tipo de información contiene."
   ],
   "id": "bcda7cb784bf0a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T14:03:21.271891Z",
     "start_time": "2024-05-15T14:03:21.239543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(X.info())\n",
    "print('=============')\n",
    "print(y.info())"
   ],
   "id": "2eb3d09993235bcb",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cómo podemos ver la tabla está compuesta por 3 variables numéricas y 1 de tipo objeto.",
   "id": "24f7607501c2e574"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.1 - Balance de clases",
   "id": "f6d062d35a16e21d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T14:03:31.050097Z",
     "start_time": "2024-05-15T14:03:31.031042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "instances_for_class_low = len(full_table[full_table[TABLE_TARGET] == \"BEGINNER\"])\n",
    "instances_for_class_high = len(full_table[full_table[TABLE_TARGET] == \"EXPERT\"])\n",
    "\n",
    "print(f\"The dataset contains {instances_for_class_low/len(full_table)*100:.4}% instances for BEGINNER class and {instances_for_class_high/len(full_table)*100:.4}% for EXPERT class.\")"
   ],
   "id": "58277bda417384ef",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.2 - Duplicados\n",
    "Miramos si la tabla tiene entradas duplicadas."
   ],
   "id": "3b9b55798c7ecbd5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T13:16:28.777285Z",
     "start_time": "2024-05-15T13:16:28.556650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "number_of_duplicated_entries = sum(full_table.duplicated(subset=TABLE_FEATURES + [TABLE_TARGET]))\n",
    "duplicated_entries_pct = number_of_duplicated_entries / len(full_table) * 100\n",
    "print(f\"The dataset contains [{duplicated_entries_pct:.4}%] of duplicated entries.\")"
   ],
   "id": "ed5e6830bbf484a6",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.3 - Valores Nulos \n",
    "Miramos si alguna de las variables que contiene la tabla contiene algún valor que sea nulo."
   ],
   "id": "63d4e4ed1d8d2c6c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T13:16:28.841307Z",
     "start_time": "2024-05-15T13:16:28.779273Z"
    }
   },
   "cell_type": "code",
   "source": "X.isnull().sum()",
   "id": "6c991380e6e0413e",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T13:16:28.940327Z",
     "start_time": "2024-05-15T13:16:28.844301Z"
    }
   },
   "cell_type": "code",
   "source": "print_empty_cols(X)",
   "id": "18b2dfadf1719a4b",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.4 - Describimos los valores de las variables de la tabla.",
   "id": "5bb94c0f81c08024"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T14:03:37.116906Z",
     "start_time": "2024-05-15T14:03:37.076385Z"
    }
   },
   "cell_type": "code",
   "source": "np.transpose(X.describe(percentiles=[.25, .50, .75], include = ['object', 'float', 'bool', 'int']))",
   "id": "74bba302a29fbfd5",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Vamos a discretizar las variables numericas, agrupando conjuntos de valores en categorias, para hacer un análisis de los datos. Para cada variable es necesaario ver la distribucion de lo valores para hacer los bins (categorias).",
   "id": "9af3eb59b924a596"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T14:10:33.251502Z",
     "start_time": "2024-05-15T14:10:33.122801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# DISCRETIZATION\n",
    "X_copy = X.copy()\n",
    "\n",
    "discretized_columns = {\n",
    "    \"fstring__number_of_elements\": [(0.0, 2.0), (2.0, 3.0), (3.0, 4.0), (4.0, inf)],  # min: 0.0 max:44.0\n",
    "    \"fstring__constants_pct\": [(0.0, 0.5), (0.5, 0.5), (0.5, 0.67), (0.67, inf)],  # min: 0.0 max: 1.0\n",
    "    \"fstring__expressions_pct\": [(0.0, 0.33), (0.33, 0.5), (0.5, 0.5), (0.5, inf)],  # min: 0.0 max: 1.0\n",
    "}\n",
    "\n",
    "discretize_columns(X_copy, discretized_columns)\n",
    "    \n",
    "# SINGLE FEATURE\n",
    "print(\"--- SINGLE FEATURE ---\")\n",
    "print(get_statistics(X_copy, ['fstring__number_of_elements'], 10))\n",
    "print(get_statistics(X_copy, ['fstring__constants_pct'], 10))\n",
    "print(get_statistics(X_copy, ['fstring__expressions_pct'], 10))\n",
    "\n",
    "\n",
    "# 2 FEATURES\n",
    "print(\"--- TWO FEATURES ---\")\n",
    "#print(get_statistics(X_copy, ['module__function_defs_pct', 'module__number_of_classes'], 10))\n",
    "\n",
    "# 3 FEATURES\n",
    "print(\"--- THREE FEATURES ---\")\n",
    "#print(get_statistics(X_copy, ['module__class_defs_pct', 'module__function_defs_pct', 'module__enum_defs_pct'], 10))"
   ],
   "id": "6baf20dd3e3ca759",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T14:10:36.489337Z",
     "start_time": "2024-05-15T14:10:36.464876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_datatypes(X:pd.DataFrame, y:pd.Series) -> (pd.DataFrame, pd.Series, [str]):\n",
    "    X = pd.get_dummies(X)\n",
    "    X = X.astype('float32')\n",
    "    y = y.apply(lambda value: 0 if value == \"BEGINNER\" else 1) # EXPERT will be 1 and BEGINNER will be 0.\n",
    "    y = y.astype('float32')\n",
    "    columns_names = X.columns.tolist()\n",
    "    return X, y, columns_names\n",
    "\n",
    "X, y, TABLE_FEATURES = normalize_datatypes(X, y)\n",
    "# Print information about the loaded table\n",
    "print(f'Features shape: {X.shape}')\n",
    "print(f'Target shape: {y.shape}')"
   ],
   "id": "5084c89dcb377a92",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Muestra la matriz de correlación de pearson entre las variables de la tabla.",
   "id": "ed8befe21328a079"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T14:10:40.955536Z",
     "start_time": "2024-05-15T14:10:40.415534Z"
    }
   },
   "cell_type": "code",
   "source": "sns.heatmap(X.corr(), annot=True)",
   "id": "dea960d18d682104",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3 - Detección de valores atípicos (outliers)\n",
    "Una vez sabemos qué datos contiene la tabla, analizaremos los valores que toma cada una de las variables de cada instancia. El objetivo es identificar posibles valores atípicos que nos dificulten la realización de futuras tareas. \n",
    "Tras su análisis, se puede concluir que un valor:\n",
    "    - **Es erróneo**. En este caso hay que tomar una decisión para cada caso, siendo los tratamientos más extendidos son listwise, pairwise, drop variables, mean/median imputation, most frequent, separate category, zero imputation, cold deck, hot deck,(stochastic) regression, k-NN and multiple imputation. Los resultados de imputación regresiva, k-NN y múltiple dan buenos resultados, aunque, como se ha indicado, es necesario el estudio en cada caso.\n",
    "    - **Es correcto, pero anómalo**. Se documenta su existencia para su posible discusión y se mantiene en el dataset. En estos casos se hace necesaria la utilización de algoritmos y estadísticos que no sean muy sensibles a dichos valores anómalos.\n",
    "\n",
    "## Univariate\n",
    "Para cada uno de los atributos se debe realizar un análisis y detección de valores atípicos, estudiando su posible causa. \n",
    "Existen diversas formas de calcular los valores anómalos. \n",
    "\n",
    "### Variables numéricas\n",
    "Para las variables numéricas, se suele identificar: \n",
    "    - a) Valor atípico leve es el que está fuera de $[Q1 - 1.5IQR, Q3 + 1.5IQR]$, donde $IQR = Q3-Q1$.\n",
    "    - b) Valor atípico extremo está fuera de $[Q1 - 3IQR, Q3 + 3IQR]$.\n",
    "\n",
    "La idea es probar con a) y si hay pocas instancias analizarlas. Si hubiese muchas, mirar b) y analizar si fuesen pocas. No hay un algoritmo o método estipulado, puesto que depende del dominio del problema y de los datos.\n",
    "\n",
    "Los límites de Tukey se basan en los cuartiles de los datos y son sensibles a la presencia de sesgo en la distribución. Cuando hay asimetría en los datos, los límites de Tukey pueden no ser tan efectivos para identificar outliers de manera equitativa en ambos extremos de la distribución. El Coeficiente de Medcouple es útil para identificar la asimetría en los datos, especialmente en presencia de valores atípicos o sesgados. Es una medida robusta porque no se ve tan afectada por valores extremos como la media y la desviación estándar. El MC puede proporcionar información adicional sobre la asimetría de la distribución, lo que te permite ajustar los límites de Tukey de manera más apropiada para tu conjunto de datos específico. Una posible variacion de los límites de Tukey teniendo en cuenta MC podria ser: \n",
    "   - Si MC es mayor que 0 (asimetría hacia la derecha):\n",
    "      - low = (q1-1.5 * math.exp(-4*mc) * iqr)\n",
    "      - high = (q3+1.5 * math.exp(3.5*mc) * iqr)\n",
    "   - Si la asimetriza es hacia la izquierda:    \n",
    "      - low = (q1-1.5 * math.exp(-3.5*mc) * iqr)\n",
    "      - high = (q3+1.5 * math.exp(4*mc) * iqr)\n",
    "\n",
    "\n",
    "### Variables categóricas\n",
    "Para las variables categóricas no existe el concepto de valor anómalo, pero sí se puede considerar en base a un análisis de frecuencia. Por ejemplo, que el uso de una categoría sea residual, pudiendo tener un 0.1% de instancias en el dataset. Para detectar estos valores, se puede fijar un valor mínimo de frecuencia en función del número posible de valores de la variable categórica (2 en el caso de una variable booleana). Por ejemplo, un umbral de $\\frac{0.2\\%}{valores}$ (0.1% en el caso de una variable booleana)"
   ],
   "id": "599c97eec7b7d283"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Analisis detallado de variables\n",
    "Para cada una de las 3 variable (1 numerica y 2 porcentuales) se hara un analisis detallado "
   ],
   "id": "132c8742057275c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Variable number_of_elements (1/3)\n",
    "Esta variable representa el número de elementos del JoinedStr. Como vimos en la descripción de la tabla esta varibale adopta valores en el rango 0 - 44. Con una media de 3.188."
   ],
   "id": "119fc307a9194a96"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T14:11:29.449647Z",
     "start_time": "2024-05-15T14:11:29.048328Z"
    }
   },
   "cell_type": "code",
   "source": "sns.stripplot(X['fstring__number_of_elements'])",
   "id": "5efd7fbb4f34563d",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T14:11:33.847365Z",
     "start_time": "2024-05-15T14:11:33.830362Z"
    }
   },
   "cell_type": "code",
   "source": "print_outliers_for_df_column(X, 'fstring__number_of_elements')",
   "id": "e5649a2923239004",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T14:11:42.531659Z",
     "start_time": "2024-05-15T14:11:42.507361Z"
    }
   },
   "cell_type": "code",
   "source": "X[X['fstring__number_of_elements'] > 10].describe(percentiles=[.25, .50, .75], include = ['object', 'float', 'bool', 'int'])",
   "id": "5c5e0e6eb4cd173",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Variable constants_pct (2/3)\n",
    "Esta variable representa la proporción de los valores usados para parametrizar el JoinedStr que son constantes. Toma los valores de 0.0 - 1.0. La media es 0.555."
   ],
   "id": "5c0a373fffec0b53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T14:12:25.735965Z",
     "start_time": "2024-05-15T14:12:25.259013Z"
    }
   },
   "cell_type": "code",
   "source": "sns.displot(X['fstring__constants_pct'], bins=[i / 100 for i in range(0, 101)])",
   "id": "9ac5d2538d99ac6a",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T14:12:40.237676Z",
     "start_time": "2024-05-15T14:12:40.224584Z"
    }
   },
   "cell_type": "code",
   "source": "print_outliers_for_df_column(X, 'fstring__constants_pct')",
   "id": "4a7a46358e270bf6",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T14:12:49.468903Z",
     "start_time": "2024-05-15T14:12:49.443746Z"
    }
   },
   "cell_type": "code",
   "source": "X[X['fstring__constants_pct'] == 1].describe(percentiles=[.25, .50, .75], include = ['object', 'float', 'bool', 'int'])",
   "id": "65828604e885a75",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Variable expressions_pct (8/13)\n",
    "Esta variable representa la proporción de valores usados para parametrizar el JoinedStr que son expresiones. Toma los valores de 0.0 - 1.0. La media es 0.444."
   ],
   "id": "a8d2d3dbd02dcea0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T14:13:36.558168Z",
     "start_time": "2024-05-15T14:13:36.119018Z"
    }
   },
   "cell_type": "code",
   "source": "sns.displot(X['fstring__expressions_pct'], bins=[i / 100 for i in range(0, 101)])",
   "id": "4d1da3a369eb0be6",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T14:13:38.906696Z",
     "start_time": "2024-05-15T14:13:38.893796Z"
    }
   },
   "cell_type": "code",
   "source": "print_outliers_for_df_column(X, 'fstring__expressions_pct')",
   "id": "5ac40e081482327",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T14:13:45.926578Z",
     "start_time": "2024-05-15T14:13:45.897108Z"
    }
   },
   "cell_type": "code",
   "source": "X[X['fstring__expressions_pct'] > 0.77].describe(percentiles=[.25, .50, .75], include = ['object', 'float', 'bool', 'int'])",
   "id": "7eed776af9068518",
   "execution_count": 18,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
